{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat Sentiment Analysis Between Me and My friend Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "     -------------------------------------- 240.9/240.9 kB 2.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234925 sha256=2f2a288e9f66fe14932e65e01fd6d6959677378414ed762913323988540bfe4f\n",
      "  Stored in directory: c:\\users\\moade\\appdata\\local\\pip\\cache\\wheels\\9a\\b8\\0f\\f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Sentimental Analysis Part\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiments = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: **The code below works for a group chat dataset or conversation with one person. All the functions defined below will prepare your data for the task of sentiment analysis as well as for any data science task**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting time from the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(s):\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
    "    return bool(result := re.match(pattern, s))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Authors or Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s) == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatapoint(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date, time = dateTime.split(\", \")\n",
    "    message = \" \".join(splitline[1:])\n",
    "    if find_author(message):\n",
    "        splitmessage = message.split(\": \")\n",
    "        author = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        author= None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datawat = []\n",
    "conversation = 'Turpsy_Cimav.txt'\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline()\n",
    "    messageBuffer = []\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                datawat.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, time, author, message = getDatapoint(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The sentimental Analysis Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Time                Author  \\\n",
      "0 2022-03-31  11:48  Sincerity_of_Purpose   \n",
      "2 2022-03-31  11:48  Sincerity_of_Purpose   \n",
      "3 2022-03-31  12:18          Turpsy_Cimav   \n",
      "5 2022-04-03  15:54          Turpsy_Cimav   \n",
      "6 2022-04-03  15:54  Sincerity_of_Purpose   \n",
      "\n",
      "                                    Message  Positive  Negative  Neutral  \n",
      "0                         Have you see this     0.000       0.0    1.000  \n",
      "2  In case you have who might be interested     0.278       0.0    0.722  \n",
      "3                             Okay,  thanks     1.000       0.0    0.000  \n",
      "5   Na people in Mexico state qualifies sha     0.000       0.0    1.000  \n",
      "6                                       Yes     1.000       0.0    0.000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(datawat, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "datawat = df.dropna()\n",
    "datawat[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in datawat[\"Message\"]]\n",
    "datawat[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in datawat[\"Message\"]]\n",
    "datawat[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in datawat[\"Message\"]]\n",
    "print(datawat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral ðŸ™‚ \n"
     ]
    }
   ],
   "source": [
    "x = sum(datawat[\"Positive\"])\n",
    "y = sum(datawat[\"Negative\"])\n",
    "z = sum(datawat[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive ðŸ˜Š \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative ðŸ˜  \")\n",
    "    else:\n",
    "        print(\"Neutral ðŸ™‚ \")\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data show that most of the messages between me and Turpsy Cimav are neutral. Which means itâ€™s neither positive nor negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
